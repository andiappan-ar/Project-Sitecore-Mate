# Mate - Sitecore Chat Search

> ğŸ§‘â€ğŸ’» Some days, AI is the teacher; other days, the eager student.\
> ğŸ¤– But these days, AIâ€™s my mate.

## Overview

**Sitecore Chat Search** is a solution designed to scrape, index, and query content from Sitecore instances, enabling semantic search and Retrieval-Augmented Generation (RAG) capabilities.\
It features a **Next.js** frontend for environment management and search, and a **Python FastAPI** backend for content processing, embeddings, and LLM interaction.

**Key features include:**

- ğŸ§© **Advanced Content Processing:** Scrapes page-level and component-level fields, with HTML cleaning for high-quality text.
- ğŸ“ **Intelligent Chunking:** Recursively splits content into optimal chunks (100â€“300 tokens, 10â€“20 overlap) for context-preserving embeddings.
- ğŸ“¦ **Vector Database Integration:** Uses ChromaDB for efficient semantic search.
- ğŸ¤¹ **Flexible LLM Support:** Works with Gemini, OpenAI, and Ollama models for RAG-based QA and summarization.
- ğŸš€ **Advanced RAG (Optional):** Supports LLM-generated summaries of pages and components for richer retrieval.
- ğŸ“¡ **Real-time Logging:** Live scraping and indexing logs from backend to frontend.
- ğŸŒ **Multilingual Support:** Handles multiple languages for international content.

---

## ğŸ—ï¸ Architecture

The solution is split into two main components:

### 1. âš›ï¸ Next.js Frontend (`Sitecore-Content-Scrapper-Website`)

- User-friendly UI for:
  - ğŸ› ï¸ Configuring Sitecore environments
  - ğŸ—‚ï¸ Scraping/indexing content
  - ğŸ–¥ï¸ Viewing logs in real-time
  - ğŸ” Vector searches and conversational RAG
- Acts as a proxy to the Python backend

### 2. ğŸ Python FastAPI Backend (`Sitecore-Chat-Search-MCP`)

- Handles:
  - ğŸ—ƒï¸ Connection to ChromaDB (`./chroma_db`)
  - ğŸ§¬ Embedding with `SentenceTransformer` (`all-MiniLM-L6-v2`)
  - ğŸ§¹ HTML processing, chunking, and validation
  - ğŸ“Š Vector DB management (add/query)
  - ğŸ§  LLM interaction for summarization and QA
  - ğŸ”— Streaming logs to frontend via SSE

---

## ğŸ“‚ Project Structure (High-Level)

```
Sitecore-Mate-Chat-Search/
â”œâ”€â”€ Sitecore-Chat-Search-MCP/           # Python FastAPI Backend
â”‚   â”œâ”€â”€ main.py                         # FastAPI app, endpoints
â”‚   â”œâ”€â”€ llm_config.py                   # LLM config and clients
â”‚   â”œâ”€â”€ prompts.py                      # Prompt templates
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ sitecore_chunking_vectordb_plan.md
â”‚   â””â”€â”€ .env
â””â”€â”€ Sitecore-Content-Scrapper-Website/  # Next.js Frontend
    â”œâ”€â”€ src/
    â”‚   â”œâ”€â”€ app/
    â”‚   â”‚   â”œâ”€â”€ api/
    â”‚   â”‚   â””â”€â”€ ...
    â”‚   â”œâ”€â”€ graphql/
    â”‚   â”œâ”€â”€ index/
    â”‚   â””â”€â”€ lib/
    â”œâ”€â”€ environments.json
    â”œâ”€â”€ next.config.ts
    â”œâ”€â”€ package.json
    â””â”€â”€ .env.local
```

---

## ğŸ§° Technologies Used

**Frontend:**

- âš›ï¸ Next.js 15.3.4
- âš›ï¸ React 19.0.0
- ğŸ¨ Tailwind CSS 4.1.11, PostCSS 8.5.6
- ğŸ”— GraphQL-Request 7.2.0
- ğŸ“ Fast-XML-Parser 5.2.5
- ğŸ†” UUID 4.x

**Backend:**

- ğŸ FastAPI
- ğŸ“ Pydantic
- ğŸ“¦ ChromaDB 3.0.6
- ğŸ§¬ Sentence Transformers (`all-MiniLM-L6-v2`)
- ğŸ² BeautifulSoup4
- ğŸª¢ Langchain
- ğŸ¤– Google Generative AI SDK
- ğŸ¤– OpenAI SDK
- ğŸ¤– Ollama

---

## ğŸš¦ Getting Started

### Prerequisites

- ğŸŸ¢ Node.js (v18+)
- ğŸŸ¢ Python (v3.9+)
- ğŸŸ¢ npm/yarn/pnpm/bun
- ğŸŸ¢ (Optional) Ollama desktop with models pulled

### 1. Backend Setup

```bash
cd Sitecore-Mate-Chat-Search/Sitecore-Chat-Search-MCP
python -m venv venv
# Activate venv, then:
pip install -r requirements.txt
# Or install individually as needed
```

- Configure `.env` (see example above for model/API options)
- Run:

```bash
uvicorn main:app --host 0.0.0.0 --port 8001 --reload
```

### 2. Frontend Setup

```bash
cd Sitecore-Mate-Chat-Search/Sitecore-Content-Scrapper-Website
npm install
# Configure .env.local with NEXT_PUBLIC_PYTHON_BASE_API_URL etc.
npm run dev
```

The app runs at [http://localhost:3000](http://localhost:3000).

---

## ğŸ Usage

1. **Access**: Visit `http://localhost:3000`
2. **Manage Environments**: Add and configure Sitecore environments.
3. **Scrape & Index**: Use the UI to trigger scraping and see real-time logs.
4. **AI Content Search**: Query via semantic search or RAG.

---

## ğŸ› ï¸ Advanced Configuration

- `CHUNK_SIZE`, `CHUNK_OVERLAP`, `N_RESULTS`, `ADVANCED_RAG_ENABLED`, and LLM provider options are in your backend `.env`.
- Frontend `.env.local` controls API URL and defaults.

---

## ğŸš€ Deployment

- **Frontend**: Deploy easily on [Vercel](https://vercel.com/) or see [Next.js deployment docs](https://nextjs.org/docs/app/building-your-application/deploying).
- **Backend**: Deploy with Gunicorn, or on cloud services like GCP, AWS, or Azure.

---

## ğŸ¤ Contribution

Contributions welcomeâ€”feel free to open issues or PRs!

## ğŸ“œ License

MIT License

---

> ğŸš§ This project is a work in progressâ€”check back for updates and new â€œmatesâ€ joining the Sitecore journey!

